{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Extractions in this notebook\n",
    "- [PDF to excel](#pdf-to-excel)\n",
    "- [Multiple pdfs to excel](#multiple-pdfs-to-excel)\n",
    "- [Load db and save to csv](#db-to-csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pdf to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted table from page 1\n",
      "Extracted table from page 2\n",
      "Extracted table from page 3\n",
      "Table saved to ./processed_files/w1.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "pdf_path = './files/W1.pdf'\n",
    "output_directory = './processed_files/'\n",
    "output_file = os.path.join(output_directory, 'w1.xlsx')\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "data = []\n",
    "headers = None  # Store headers to maintain consistency\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page_num, page in enumerate(pdf.pages, start=1):\n",
    "        table = page.extract_table()\n",
    "        if table:\n",
    "            if headers is None:  # Set headers from the first page\n",
    "                headers = table[0]  \n",
    "            data.extend(table[1:])  # Append data (excluding headers)\n",
    "            print(f\"Extracted table from page {page_num}\")\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "if data:\n",
    "    df_pdf = pd.DataFrame(data, columns=headers)  # Apply headers\n",
    "    df_pdf.to_excel(output_file, index=False)\n",
    "    print(f\"Table saved to {output_file}\")\n",
    "else:\n",
    "    print(\"No tables found in the PDF.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple PDFs to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "directory_path = './mock4/mock_roe_4/'\n",
    "output_directory = './processed_files/'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get all PDF files in the directory\n",
    "pdf_files = [f for f in os.listdir(directory_path) if f.endswith('.pdf')]\n",
    "\n",
    "dfs = []\n",
    "for filename in pdf_files:\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Processing: {filename}\")  # Logging current file\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            for page_num, page in enumerate(pdf.pages, start=1):\n",
    "                table = page.extract_table()\n",
    "                if table:  # Ensure a table is found\n",
    "                    df = pd.DataFrame(table[1:], columns=table[0])  # Set headers from first row\n",
    "                    dfs.append(df)\n",
    "                    print(f\"Extracted table from {filename}, Page {page_num}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Check if any tables were extracted before concatenation\n",
    "if dfs:\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    output_file = os.path.join(output_directory, 'all_tables.xlsx')\n",
    "    df_all.to_excel(output_file, index=False)\n",
    "    print(f\"Tables saved to {output_file}\")\n",
    "else:\n",
    "    print(\"No tables extracted from PDFs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_directory, 'all_tables.csv')\n",
    "df_all.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# db to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (sqlite3.OperationalError) unable to open database file\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sql\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define database path and output directory\n",
    "db_path = \"./mock4/mock_roe_4/violations.db\"\n",
    "output_directory = \"./processed_files/\"\n",
    "output_file = os.path.join(output_directory, \"violations.csv\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Connect to the SQLite database using SQLAlchemy\n",
    "    engine = sql.create_engine(f\"sqlite:///{db_path}\")\n",
    "    \n",
    "    # Read data from the 'violations' table\n",
    "    db_data = pd.read_sql(\"SELECT * FROM violations\", engine)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    db_data.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data successfully extracted and saved to {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
